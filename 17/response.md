AI's impacts on scholarship (as opposed to education) are almost entirely positive.  The two positive impacts are (a) automating large quantities of work and (b) predictive rendering.  The one negative impact is (c) errors caused by trusting the accuracy of AI too much.

(a) Similar to the latin formatting algorithm Daniel was talking about in class, automating large quantities of intellectual drudge work allows human researchers to spend more time developing interprative ideas using larger quantities of source material.

(b) AI could be used to create predictive renerings of things like partially destroyed archaeological sites, or to seek other patterns in data, in a way that would be very hard to replicate with a conventional pre-AI algorithms.

(c) If an AI is used in place of a human before the AI actually performs the task as well as a human, errors can occur.  In the case of self-driving cars, these errors are obvious to everybody and carefully vetted by many third parties.  In the case of scholarship, it is possible that errors of an immature AI could be accepted as truth because the lower stakes and less obvious malfunctions could be overlooked in peer review.
